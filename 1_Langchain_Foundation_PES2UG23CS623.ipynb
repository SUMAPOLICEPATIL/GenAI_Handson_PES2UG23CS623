{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZqV6EQqsJuf",
        "outputId": "97ef38cd-114e-4bc5-e1a4-1478daf087b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/111.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/66.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.5/500.5 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.1/158.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install python-dotenv --upgrade --quiet langchain langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "import getpass\n",
        "import os\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "  os.environ[\"GOOGLE_API_KEY\"]=getpass.getpass(\"Enter your Google API Key:\")"
      ],
      "metadata": {
        "id": "TWTRt5BgsrJu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm_focused=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\",temperature=0.0)\n",
        "\n",
        "llm_creative=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\",temperature=1.0)"
      ],
      "metadata": {
        "id": "y0VtScPKvH_N"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Define the word 'Idea' in one sentence.\"\n",
        "print(\"---FOCUSED (Temp=0)---\")\n",
        "print(f\"Run 1: {llm_focused.invoke(prompt).content}\")\n",
        "print(f\"Run 2: {llm_focused.invoke(prompt).content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTxfe3hHv_SV",
        "outputId": "c485be1a-d41f-4504-b9f2-d9b43e1c9a06"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---FOCUSED (Temp=0)---\n",
            "Run 1: An idea is a thought, concept, or suggestion that is formed or exists in the mind.\n",
            "Run 2: An idea is a thought, concept, or suggestion that is formed or exists in the mind.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Define the word 'Idea' in one sentence.\"\n",
        "print(\"---FOCUSED (Temp=1)---\")\n",
        "print(f\"Run 1: {llm_creative.invoke(prompt).content}\")\n",
        "print(f\"Run 2: {llm_creative.invoke(prompt).content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOpbCXFayKyI",
        "outputId": "c33b0f95-4226-4ce3-89b3-d8e9a096af5c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---FOCUSED (Temp=1)---\n",
            "Run 1: An idea is a mental conception, thought, or plan that can be expressed, developed, or acted upon.\n",
            "Run 2: An idea is a thought, concept, or mental impression originating in the mind.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "import getpass\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "  os.environ[\"GOOGLE_API_KEY\"]=getpass.getpass(\"Enter your Google API Key:\")\n",
        "llm=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
      ],
      "metadata": {
        "id": "KcZvcLgOxeM_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage,HumanMessage\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a nice Human Being.Kindness and softness makes human\"),\n",
        "    HumanMessage(content=\"What are states of India\")\n",
        "]\n",
        "\n",
        "response = llm.invoke(messages)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7IgL3aZywQy",
        "outputId": "e7b27d2d-00f2-4a91-8a5b-c3d51c6f4138"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "India currently has **28 states** and 8 Union Territories.\n",
            "\n",
            "Here are the 28 states of India:\n",
            "\n",
            "1.  Andhra Pradesh\n",
            "2.  Arunachal Pradesh\n",
            "3.  Assam\n",
            "4.  Bihar\n",
            "5.  Chhattisgarh\n",
            "6.  Goa\n",
            "7.  Gujarat\n",
            "8.  Haryana\n",
            "9.  Himachal Pradesh\n",
            "10. Jharkhand\n",
            "11. Karnataka\n",
            "12. Kerala\n",
            "13. Madhya Pradesh\n",
            "14. Maharashtra\n",
            "15. Manipur\n",
            "16. Meghalaya\n",
            "17. Mizoram\n",
            "18. Nagaland\n",
            "19. Odisha\n",
            "20. Punjab\n",
            "21. Rajasthan\n",
            "22. Sikkim\n",
            "23. Tamil Nadu\n",
            "24. Telangana\n",
            "25. Tripura\n",
            "26. Uttar Pradesh\n",
            "27. Uttarakhand\n",
            "28. West Bengal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a translator. Translate {input_language} to {output_language}.\"),\n",
        "    (\"human\", \"{text}\")\n",
        "])\n",
        "\n",
        "# We can check what inputs it expects\n",
        "print(f\"Required variables: {template.input_variables}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWLf5zj8_TWj",
        "outputId": "9ec0dc17-d230-4952-ed86-f917ee732f6f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Required variables: ['input_language', 'output_language', 'text']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()\n",
        "\n",
        "# Raw Message\n",
        "raw_msg = llm.invoke(\"Hi\")\n",
        "print(f\"Raw Type: {type(raw_msg)}\")\n",
        "\n",
        "# Parsed String\n",
        "clean_text = parser.invoke(raw_msg)\n",
        "print(f\"Parsed Type: {type(clean_text)}\")\n",
        "print(f\"Content: {clean_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jK8JXUDS_dOU",
        "outputId": "c7078863-1ca1-48cf-bee7-df1a4a448442"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw Type: <class 'langchain_core.messages.ai.AIMessage'>\n",
            "Parsed Type: <class 'langchain_core.messages.base.TextAccessor'>\n",
            "Content: Hello! How can I help you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "import getpass\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "  os.environ[\"GOOGLE_API_KEY\"]=getpass.getpass(\"Enter your Google API Key:\")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
        "templete = ChatPromptTemplate.from_template(\"Tell me a fun fact about {topic}.\")\n",
        "parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "IJjMzobF0I4X"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_value = templete.invoke({\"topic\":\"Boys\"})\n",
        "response_obj = llm.invoke(prompt_value)\n",
        "final_text = parser.invoke(response_obj)\n",
        "print(final_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWvHfc8K1r45",
        "outputId": "93734535-090e-4ce2-f83f-3f61c9383c65"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a fun fact about boys:\n",
            "\n",
            "Did you know that during puberty, a boy's vocal cords lengthen and thicken significantly, causing his voice to \"break\" and drop in pitch, sometimes by an entire octave? It's like a natural instrument retuning itself!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = templete | llm | parser\n",
        "print(chain.invoke({\"topic\":\"Girls\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lkYI42c2QGX",
        "outputId": "2d48900d-e2c6-4994-aa83-c04459e1d402"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a fun fact about girls:\n",
            "\n",
            "**Girls often develop language skills, including speaking and reading, earlier and faster than boys!**\n",
            "\n",
            "Studies show that on average, girls tend to have a larger vocabulary and use more complex sentence structures at a younger age, and they often hit communication milestones like first words and full sentences sooner.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from datetime import datetime\n",
        "\n",
        "# Current year\n",
        "current_year = datetime.now().year\n",
        "\n",
        "# Model\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.0)\n",
        "\n",
        "# Prompt Template\n",
        "template = ChatPromptTemplate.from_template(\n",
        "    f\"\"\"\n",
        "    You are a movie expert.\n",
        "    Tell me the release year of the movie {{movie}}.\n",
        "    Then calculate how many years ago it was from {current_year}.\n",
        "    Respond in this format:\n",
        "    Movie: <name>\n",
        "    Release Year: <year>\n",
        "    Years Ago: <calculation>\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# One-line LCEL chain\n",
        "chain = template | llm | StrOutputParser()\n",
        "\n",
        "# Run it\n",
        "print(chain.invoke({\"movie\": \"Stranger Things\"}))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4iikxuM2hPu",
        "outputId": "b180a237-e4f9-43a0-c96e-9e4196d4d6d0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Movie: Stranger Things (TV Series)\n",
            "Release Year: 2016\n",
            "Years Ago: 2026 - 2016 = 10 years ago\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1KsruD7329Rb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}